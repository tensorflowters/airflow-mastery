# =============================================================================
# Airflow Local Development Environment Variables
# =============================================================================
#
# SECURITY NOTICE:
# 1. Copy this file to .env: cp .env.example .env
# 2. Generate secure values for all keys marked [GENERATE]
# 3. NEVER commit .env to version control
# 4. For production, use proper secrets management (Vault, AWS Secrets Manager, etc.)
#
# =============================================================================

# -----------------------------------------------------------------------------
# DATABASE CONFIGURATION
# -----------------------------------------------------------------------------
# PostgreSQL credentials for the metadata database
# For production: use external managed database (RDS, Cloud SQL, etc.)

POSTGRES_USER=airflow
POSTGRES_PASSWORD=changeme_use_strong_password_min_32_chars
POSTGRES_DB=airflow

# Full connection string (constructed from above values)
# Format: postgresql+psycopg2://<user>:<password>@<host>/<database>
AIRFLOW_DB_CONNECTION=postgresql+psycopg2://airflow:changeme_use_strong_password_min_32_chars@postgres/airflow

# -----------------------------------------------------------------------------
# AIRFLOW SECURITY KEYS [GENERATE THESE]
# -----------------------------------------------------------------------------

# Fernet Key - REQUIRED for encrypting connections and variables
# Generate with: python3 -c "from cryptography.fernet import Fernet; print(Fernet.generate_key().decode())"
# Example format: 81HqDtbqAywKSOumSha3BhWNOdQ26slT6K0YaZeZyPs=
AIRFLOW_FERNET_KEY=CHANGE_ME_GENERATE_WITH_COMMAND_ABOVE

# Webserver Secret Key - REQUIRED for session management and CSRF protection
# Generate with: python3 -c "import secrets; print(secrets.token_hex(32))"
# Example format: a1b2c3d4e5f6g7h8i9j0k1l2m3n4o5p6q7r8s9t0u1v2w3x4y5z6
AIRFLOW_WEBSERVER_SECRET_KEY=CHANGE_ME_GENERATE_WITH_COMMAND_ABOVE

# -----------------------------------------------------------------------------
# ADMIN USER CREDENTIALS
# -----------------------------------------------------------------------------
# Initial admin user created on first startup
# IMPORTANT: Change password immediately after first login in production

AIRFLOW_ADMIN_USERNAME=admin
AIRFLOW_ADMIN_PASSWORD=changeme_strong_password_here
AIRFLOW_ADMIN_EMAIL=admin@example.com
AIRFLOW_ADMIN_FIRSTNAME=Airflow
AIRFLOW_ADMIN_LASTNAME=Admin

# -----------------------------------------------------------------------------
# OPTIONAL CONFIGURATION
# -----------------------------------------------------------------------------

# Executor type (LocalExecutor for development, KubernetesExecutor for production)
AIRFLOW_EXECUTOR=LocalExecutor

# Timezone for DAG scheduling
AIRFLOW_TIMEZONE=UTC

# Whether to load example DAGs (disable in production)
AIRFLOW_LOAD_EXAMPLES=false

# Whether new DAGs are paused by default
AIRFLOW_DAGS_PAUSED_AT_CREATION=true

# -----------------------------------------------------------------------------
# DEVELOPMENT-ONLY DEFAULTS (DO NOT USE IN PRODUCTION)
# -----------------------------------------------------------------------------
# The following values are weak defaults suitable ONLY for local development.
# For any shared or production environment, generate new values above.
#
# Quick start for local development ONLY:
#   1. Copy this file to .env
#   2. Keep the default values (insecure but functional)
#   3. Run: docker-compose up -d
#
# For anything beyond local testing:
#   1. Generate all [GENERATE] values using the commands above
#   2. Use strong passwords (32+ characters, mixed case, numbers, symbols)
#   3. Store credentials securely (secrets manager, encrypted vault)
# -----------------------------------------------------------------------------
